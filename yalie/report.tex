\documentclass[twocolumn]{article}
\usepackage{amsmath,graphicx,amsfonts,amssymb}
\usepackage{}
\title{Yet Another Lisp Interpreting Experiment}
\author{John O'Connor, Paul Hudak}
\date{}

\begin{document}

\newcommand{\next}{\operatorname{next}}
\newcommand{\invoke}{\operatorname{invoke}}
\newcommand{\lookup}{\operatorname{lookup}}
\newcommand{\wrap}{\operatorname{wrap}}
\newcommand{\parse}{\operatorname{parse}}

\newcommand{\eval}{\texttt{eval}}
\newcommand{\call}{\texttt{call}}
\newcommand{\msg}{\texttt{msg}}

\newcommand{\lb}{\left<}
\newcommand{\rb}{\right>}

\maketitle

\section*{Introduction}
One of the historical attractions of the Lisp family of programming
languages has been their flexibility. Lisp was one of the first
languages to include dynamic typing, and Lisp macros allow the
programmer to create new binding forms and control structures. This
flexibility is one of the reasons for Lisp's popularity in the AI
community. Programmers can implement domain-specific mini-languages
without losing the infrastructure of a full language implementation.

Another strength of Lisp is its elegance. The S-expression syntax
allows Lisp to treat lists as code. Thus Lisp macros, by constructing
and returning lists of symbols, actually return instructions to be
executed. This is one of the more confusing aspects of Lisp for
newcomers, to be sure, but it also simplifies the language in an
important sense. Where most languages have code and data, Lisp has
only data. In the long run, fewer ``moving parts'' means fewer
distinct concepts that a programmer needs to keep in mind to
understand his language.

More recent developments, however, have seen Lisp fall behind. In
particular, the Smalltalk language demonstrated that it is possible to
treat everything in a language as an ``object.'' The popular Python
and Ruby languages have adopted many concepts from Smalltalk with
great success. Several object-oriented variants of Lisp have been
developed, including the Common Lisp Object System, but these have not
achieved nearly the same popularity. We wish to suggest that one of
the failings of various Lisp object systems is that they are built for
the wrong reasons.

Through object-orientation, Smalltalk was able to achieve greater
flexibility and greater simplicity. These goals are essentially
orthogonal to the goal of facilitating an object-oriented programming
style. Lisp object systems have attempted the latter, and as a result
they have generally made their languages more complicated and less
consistent. We believe that object-orientation can greatly enhance
Lisp's core strengths, but only if these concepts are introduced
consistently throughout the entire language.

This is the intention of Yet Another Lisp Interpreting Experiment (or,
``Yalie''). Our goal is to demonstrate a Lisp variant in which
everything is an object and all function calls are based on message
passing. In doing this, we hope to make the language less complicated,
rather than more so. An interactive interpreter for Yalie, written in
Python, accompanies this paper. What follows is a formal description
of the language implemented in that interpreter.  For a practical
description, please see the accompanying README file. This paper
assumes the reader is familiar with a modern Lisp dialect such as
Scheme or Common Lisp.

\section*{Concepts}
\subsection*{Object-based Languages}
Broadly speaking, there are two major categories of object-oriented
languages\cite{Abadi}. The most familiar and widely used are the
``class-based'' languages, including C++, Java, and Smalltalk. The
other category is ``object-based'' or ``prototype-based'' languages,
like JavaScript and Lua. Class-based languages distinguish classes
from the objects that belong to them, and inheritance is accomplished
within the class hierarchy. Object-based languages omit this
distinction, and instead allow objects to inherit from one another and
produce their own clone or child objects. In practice, object-based
languages often approximate classes by using certain objects solely
for inheritance, and for that reason---and because of the wider
popularity of class-based languages---some have argued that making
classes an explicit part of the language is more
convenient\cite{Bruce}. Our primary purpose here, though, is
simplicity and consistency, so ours will be an object-based semantics.

\subsection*{Message Passing}
As a demonstration of the consistency possible with object
orientation, all of the semantics of our language aside from literal
syntax is based on message passing. This is very different from
traditional Lisp semantics and requires some explanation. For an
example, suppose we wish to evaluate the S-expression
\[ \texttt{(+ 1 2)}. \] That is a list object (a series of cons
objects, in fact) containing a symbol object and two integer
objects. Evaluation begins by calling the \eval\ method of the list. As
with all Lisp dialects, S-expressions represent function calls, so the
\eval\ method of a list calls the \eval\ method of its first element,
expecting a function or special form object of some kind. The \eval\
method of the \texttt{+} symbol returns the binding of that symbol in
the calling scope, which is indeed a function. The list \eval\ then
invokes the \call\ method of that object, passing the remainder of the
list as arguments, and finally returns $3$.

Tradditionally, S-expressions represented function calls because a
central evaluation loop interpreted them that way. Here they represent
function calls because their \eval\ method carries out a
function call. Note also that functions and forms in Yalie are just
ordinary objects with a defined \call\ method. We will
construct a few predefined global functions and forms in Yalie, and
these will be just ordinary objects with \call\ methods that we
define usefully.

Another key difference in this function is the way \texttt{+} is
defined, which is not immediately visible. Rather than being a builtin
operation that knows about integers, \texttt{+} simply calls invokes a
method of its arguments. This method is also named \texttt{+}, though
it resides in method tables rather than the global scope as the
\texttt{+} function does. One of the global functions we will define
is \msg, which allows the user to invoke methods explicitly. Expressed
using \msg, the S-expression we considered above can be rewritten as
\[\texttt{(msg 1 + 2)}.\]
That is, adding $1$ to $2$ means sending the \texttt{+} message to the
object $1$ with the argument $2$. In full detail, the \eval\ method of
that list evaluates the symbol \msg, whose value is a special form
object with a \call\ method that passes that messages. When that \call\
method is invoked, it evaluates its first argument, the $1$ object,
and invokes the method named by its second argument, passing the rest
of its arguments to that method.

Something to keep in mind as we continue is that anything defined as a
method can be invoked explicitly or even redefined by the user. Thus,
the first S-expression could be rewritten again as
\[ \texttt{(msg + call 1 2)}, \]
and the second could even be rewritten
\[ \texttt{(msg msg call 1 + 2)}. \] The latter is not particularly
useful, but it illustrates what is going on ``under the hood.'' We
will discuss the facilities for defining and redefining new methods in
later sections.

\subsection*{Semantic Machinery}
The semantics of our language will be built from several different
components. Persistent, often mutable objects will be the core of our
language, so evaluation will use both a scope and a store. A scope is
a map from names to positive integer values. We will refer to these
integers suggestively as pointers. We denote scopes by the variable
$\varphi$, with the global scope---that is, the builtin scope in which
program evaluation begins---denoted by $\Phi$. A store is then a map
from these pointers to objects, and this indirection allows us to
mutate objects by modifying the store. We denote a store by the
variable $\sigma$, and the global store, analogous to the global
scope, is denoted by $\Sigma$. We will frequently refer to the
pointers to certain builtin objects using capitalized names like
\textsf{ROOT}, the prinary object at the top of the inheritance
hierarchy, or \textsf{INT}, the object from which all integers
inherit. The objects to which these pointers refer are then written
$\Sigma(\mathsf{ROOT})$ and $\Sigma(\mathsf{INT})$. The actual values
of these pointers are arbitrary, so long as they are constant and
unique. The only other way we will refer to pointer values is the
$\next(\sigma)$ function, whose value is the smallest pointer not
currently in the domain of $\sigma$. We will generally use the
variable $\omega$ to denote pointers, though we will also use the
variable $a$ to refer to arguments to functions and $e$ to refer to
the results of evaluation.

An object has four important properties. It has a parent object from
which it inherits method functions, a map of its own from names to
method functions, a scope of member elements, and a field for
underlying data such as an integer or a name. We will define objects
as ordered 4-tuples, written
\[ \lb p, \mu, \varphi, d \rb .\]
For example, the integer five would be represented as
\[ \lb \mathsf{INT}, \mu_0, \varphi_0, 5 \rb, \]
where $\mu_0$ is the empty function map, and $\varphi_0$ is the empty
scope. We will frequently use the notation $\mu_{\sigma(\omega)}$ and
$\varphi_{\sigma(\omega)}$ to refer to the function map or scope
elements of the object $\sigma(\omega)$.

We have already mentioned the function $\next(\sigma)$, but we should
like to introduce two more semantic function here that we will use
later. The first is our function for looking up methods, using the
``message-passing'' terminology of Simula and Smalltalk. When a method
cannot be found in the method table of a given object, it's parent is
queried recursively.
\begin{multline*} \lookup(\text{``msg''}, \sigma, \omega) = \\
\begin{cases}
  \varphi_{\sigma(\omega)} &\text{if } \text{``msg''} \in
  \operatorname{Domain}(\varphi_{\sigma(\omega)}) \\
    \lookup(\text{``msg''},\sigma,p_{\sigma(\omega)}) &\text{otherwise}
  \end{cases}
\end{multline*}

The second function we need to define at the moment is the semantic
function for invoking methods. We mentioned the global \msg\ object in
the preceding section, and this semantic function will eventually form
the core of that object's \call\ method, in addition to being used
explicitly by many other methods. The invocation of a method requires
the current store and scope as well as pointers to invoking object and
all the arguments of the method, the latter expressed as an ordered
tuple. Method functions will be defined so that the value of an
invocation is a 3-tuple containing the new store and scope and a
pointer to the object returned by the method.
\begin{multline*}
  \invoke( \text{``msg''}, \sigma, \phi, \lb a_1,\ldots a_n\rb) = \\
  (\lookup(\text{``msg''}, \sigma, \omega))(\sigma,\phi,\omega,
  \lb a_1,\ldots a_n \rb )
\end{multline*}
  
\section*{Syntax}

With the goal of unifying code and data, we will take a less
conventional approach to specifying the semantics of our
language. First, we will describe the translation from syntax to
literal objects. Then we will define the methods available to those
objects. Invocation of the \eval\ methods of our code will be
responsible for most of the work done by a program, and ultimately our
complete denotational operator, $[\![-]\!]$, will be the simple
combination of the parse and invoke operations with $\Sigma$ and
$\Phi$.

\subsection*{Literal Objects}
Yalie contains only three literal objects: integers, symbols, and
lists. Integers are written as strings of decimal digits. Symbols are
written as any string of characters (other than those defined as
punctuation in this section) that is not an integer. Lists are written
as a sequence of whitespace-separated literals enclosed by matching
parentheses. We can define the parsing function as taking for
arguments a code snippet and an initial store, and returning an
updated store and the number referring to the newly created object in
that store.  Integers are parsed as
\begin{multline*}
\parse(\texttt{NUM},\sigma) =
\lb\next(\sigma),[\sigma|\operatorname{next}(\sigma) \rightarrow\right. \\
\left.\lb\mathsf{INT}, \mu_0, \varphi_{\Sigma(\mathsf{INT})}, \texttt{NUM}\rb]\rb,
\end{multline*}
and symbols are parsed as
\begin{multline*}
  \parse(\texttt{SYM},\sigma) =
  \lb\next(\sigma),[\sigma|\operatorname{next}(\sigma) \rightarrow\right. \\
\left.\lb\mathsf{SYMBOL}, \mu_0, \varphi_{\Sigma(\mathsf{SYMBOL})},
  \texttt{SYM}\rb]\rb.
\end{multline*}
Note that the parent of each new integer or symbol object is the
global integer or symbol object, respectively. These objects are
created with an empty method table, meaning that they inherit all of
their methods by default. They also copy the member scope of their
parent, which is empty by default unless modified by the user.

Finally, lists are parsed into ``cons'' objects, as is traditional for
Lisp languages. The underlying data field, $d$, of these cons objects
will be an ordered pair of the form $\lb a,b\rb$, and they will be
chained together to form linked lists terminated in a ``nil''
object. List parsing will be defined in two steps. First, the empty
list is parsed as
\begin{multline*}
  \parse(\texttt{()},\sigma) = \lb\next(\sigma),
  [\sigma|\operatorname{next}(\sigma) \rightarrow \right.\\
\left.\lb\mathsf{NIL}, \mu_0, \varphi_{\Sigma(\mathsf{NIL})}, \o\rb]\rb.
\end{multline*}
This is similar to the integer and symbol parsing operations above,
though note that the data field of nil objects is unimportant. List
parsing for nonempty lists can now be defined recursively.
\begin{multline*} \parse(\texttt{(a b \ldots\ z)},\sigma) = \lb
  \next(\sigma''),[\sigma''|\operatorname{next}(\sigma'')
  \rightarrow\right. \\\left.\lb\mathsf{CONS}, \mu_0,
  \varphi_{\Sigma(\mathsf{CONS})},
  \lb F, R \rb \rb ] \rb
\end{multline*}
where
\begin{align*}
  \lb F, \sigma' \rb &= \parse( \texttt{a}, \sigma ) \\
  \lb R, \sigma'' \rb &= \parse( \texttt{(b \ldots\ z)}, \sigma')
\end{align*}
This expression can be slightly confusing. $F$ denotes the pointer to
the first parsed object in a list, and $\sigma'$ is the store after
parsing that object. $R$ then denotes the pointer to the rest of the
list, acquired recursively, and $\sigma''$ is the store after all that
parsing is done. The whole list is finally assembled by adding to
$\sigma''$ the cons cell at the head of the list.

\subsection*{Syntactic Sugar}
In addition to these literals, we define some extra translational
syntax for convenience. First we give a dot operator for message
passing, and second we will provide a quote operator to protect
objects from automatic evaluation.

Message passing is invoked by the expression
\[\texttt{(msg foo msgForFoo [args...])},\]
so we allow the period operator to translate into that
S-expression. Without parentheses, \texttt{a.b} translates We let \texttt{a.b} translate to \texttt{(msg a b)} and
\texttt{(a.b c d...)} translate to \texttt{(msg a b c d...)}. When
there are multiple consecutive infixed objects at the front of an
S-expression, we evaluate from left to right and allow the final infix
to capture the expression. Thus \texttt{(a.b.c d e)} translates to
\texttt{(msg (msg a b) c d e)}. We also define the single quote as a
prefix operator that takes precedence over the period, and we
translate \texttt{`a} to \texttt{(quote a)}. Both \texttt{msg} and
\texttt{quote} will be defined below.

\section*{Builtin Objects and Methods}
The meat of the Yalie language is in its builtin objects and
methods. As we have seen, object literals all inherit from parent
objects that will be exposed to the user for potential
modification. These parent objects will have methods defined for their
children to inherit.

We will formally specify only a few methods here. A short description
of all the methods used by the interpreter can be found in the
accompanying README file.

In order to specify these methods, we will need a few helper
functions. The lookup function, $L$, takes a store, an object
reference, and a method name and returns the method of that name
belonging to the closest ancestor of the object.
\begin{multline*}
  L(\sigma,o,\text{``name''}) = \phi_1(\text{``name''}) \text{ if
  ``name''} \in \phi_1 \\\text{else }L(\sigma,p,\text{``name''}),
\end{multline*}
where $\sigma(o)=(p,\phi_1,\phi_2,d)$.

The method invoker, $M$, returns the value of a method call on a given
object under a given scope and store. That is, it invokes functions
which return an object reference, a new scope, and a new store.
\begin{multline*} M(\phi,\sigma,o,\text{``name''},\left<a_1,\ldots a_n\right>)
 =\\ f( \phi, \sigma, o, \left<a_1, \ldots a_n\right> )
\end{multline*}
where $f = L(\sigma,o,\text{``name''})$.

Lastly, our wrapper function, $W$, takes a function of some arguments
and returns a function that implicitly evaluates those arguments
before beginning. This is necessary because the ``call'' function will
need to circumvent implicit evaluation of arguments. Evaluation is
accomplished by the ``eval'' method, which each object will define.
\begin{multline*}
W(f)(\phi,\sigma,o,\left<a_1,\ldots a_n\right>) =
f(\phi,\sigma,o,\left<e_1,\ldots e_n\right>)
\end{multline*}
where $e_i = M(\phi,\sigma,a_i,\text{``eval''},\left<\right>)$.

Now we can define some of the important methods. The basic
\eval\ function simply returns the value of the caller.
\[ \phi_{\text{ROOT}}(\text{``eval''})(\phi,\sigma,o,\left<\right>) = 
(o,\phi,\sigma) \]
where $\sigma_{\text{ROOT}}$ is the method scope of the root
object. Most objects inherit this method, with the exception of
symbols and lists. The symbol ``eval'' method is
\[ \phi_{\text{SYMBOL}}(\text{``eval''})(\phi,\sigma,o,\left<\right>) = 
(\phi(d_{\sigma(o)}),\phi,\sigma). \]
Finally, for lists,
\[ \phi_{\text{CONS}}(\text{``eval''})(\phi,\sigma,o,\left<\right>) =
M(\phi',\sigma',e_1,\text{``call''},\left<a_2,\ldots a_n\right>) \]
where $\left< a_1,\ldots a_n\right>$ are the contents of the list, and
$(e_1,\phi',\sigma') = M(\phi,\sigma,a_1,\text{``eval''},\left<\right>)$.

For an example of the use of the $W$ wrapper, the method for addition
over the integers is
\[ \phi_{\text{INT}}(\text{``eval''}) = W
\lambda(\phi,\sigma,o,\left<e_1\right>).(n,\phi,\sigma') \] where
$n = (\text{INT},\phi_0,{\phi_2}_{\text{INT}},d_{e_1}+d_{\sigma(o)})$ and
$\sigma' = [\sigma|\operatorname{next}(\sigma)\rightarrow n]$.

Finally, here is the critical ``call'' method for the \texttt{msg}
function object.
\begin{multline*}
  \phi_{\text{MSG}}(\text{``call''})(\phi,\sigma,o,\left<a_1,a_2,
  \ldots a_n \right>) = \\M(\phi,\sigma,a_1,d_{a_2}, \left<a_3,\ldots
  a_n\right>).
\end{multline*}


\section*{Conclusions}
Several different interpreters were created at different stages in
this project, but the ``call'' and ``eval'' semantics were only
included in the final version. The ease of coding these semantics
relative to the more standard approach (using a central eval loop) was
striking, both in reduced programming time and in reduced debugging
time. These semantics are also far easier to modify than any previous.

The language is still very small, so some of the benefits of the
object-oriented approach are not yet apparent. One tangible benefit is
that, despite having gutted the entire language to allow the
ubiquitous use of objects, the only difference visible in the global
namespace is the existence of the \msg\ function. All other
object-oriented functionality is confined within the method spaces. If
we were to further extend the language---with strings and file handles
for example---we would see the same benefits repeated, with new
functionality mostly confined to method spaces. Not only does this
approach keep the global namespace free of clutter, it also provides
helpful documentation in the form of method lists.

The example of adding a factorial method to the entire set of integers
(see README) demonstrates the flexibility of the object-oriented
approach, and though the language is still small, the improved
consistency of the semantics has already made itself felt during the
implementation process. We look forward to finding new ways of
leveraging the object abstraction, both by itself and in conjunction
with Lisp's macro system.

\begin{thebibliography}{9}
\bibitem{Abadi} M. Abadi and L. Cardelli. \textit{A Theory of Objects.} New
  York: Springer, 1996.

\bibitem{Bruce} K. B. Bruce. \textit{Foundations of Object-Oriented
    Languages.} Cambridge, Massachusetts: MIT Press, 2002.
\end{thebibliography}



\end{document}
