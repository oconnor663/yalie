\documentclass[twocolumn]{article}
\usepackage{amsmath,graphicx,amsfonts,amssymb}
\usepackage{sverb}
\title{Yet Another Lisp Interpreting Experiment}
\author{John O'Connor}
\date{}

\begin{document}

\newcommand{\next}{\operatorname{next}}
\newcommand{\invoke}{\operatorname{invoke}}
\newcommand{\lookup}{\operatorname{lookup}}
\newcommand{\wrap}{\operatorname{wrap}}
\newcommand{\parse}{\operatorname{parse}}

\newcommand{\eval}{\texttt{eval}}
\newcommand{\call}{\texttt{call}}
\newcommand{\msg}{\texttt{msg}}

\newcommand{\lb}{\left<}
\newcommand{\rb}{\right>}

\newcommand{\ptr}{\sf \small}
\newcommand{\subptr}{\sf}

\maketitle

\section*{Introduction}
One of the historical attractions of the Lisp family of programming
languages has been their flexibility. Lisp was one of the first
languages to include dynamic typing, and Lisp macros allow the
programmer to create new binding forms and control structures. This
flexibility is one of the reasons for Lisp's popularity in the AI
community. Programmers can create domain-specific mini-languages
on top of a full Lisp implementation.

Another strength of Lisp is its elegance. The S-expression syntax
allows Lisp to treat lists as code. Thus Lisp macros, by constructing
and returning lists of symbols, actually return instructions to be
executed. This is one of the more confusing aspects of Lisp for
newcomers, to be sure, but it also simplifies the language in an
important sense. Where most languages have code and data, Lisp has
only data. In the long run, fewer ``moving parts'' means fewer
distinct concepts that a programmer needs to keep in mind to
understand his language.

More recent developments, however, have seen Lisp fall behind. In
particular, the Smalltalk language demonstrated that it is possible to
treat everything in a language as an ``object.'' Python and Ruby
languages have adopted many concepts from Smalltalk with great
success. Though several object-oriented variants of Lisp have been
developed, including the Common Lisp Object System, these have not
achieved nearly the same widespread use. We wish to suggest that one
of the failings of various Lisp object systems is that they are built
for the wrong reasons.

Through object-orientation, Smalltalk was able to achieve both
flexibility and simplicity. These goals are essentially orthogonal to
the goal of facilitating an object-oriented programming (OOP)
style. Lisp object systems have attempted the latter, and as a result
they have generally made their languages more complicated and less
consistent. We believe that objects can greatly enhance Lisp's core
strengths, but only if these concepts are introduced consistently
throughout the entire language.

This is the intention of Yet Another Lisp Interpreting Experiment (or,
``Yalie''). Our goal is to demonstrate a variant of Lisp in which
everything is an object and all function calls are based on message
passing. In doing this, we hope to make the language less complicated,
rather than more so. An interactive interpreter for Yalie, written in
Python, accompanies this paper. What follows is a formal description
of the language implemented in that interpreter. For a practical
description with examples, please see the accompanying README file,
reprinted here in the appendices. This paper assumes the reader is
familiar with a modern Lisp dialect such as Scheme or Common Lisp.

\section*{Concepts}
\subsection*{Object-based Languages}
Broadly speaking, there are two major categories of object-oriented
languages \cite{Abadi}. The most common are ``class-based'' languages,
including C++, Java, and Smalltalk. The other category is
``object-based'' or ``prototype-based'' languages, like JavaScript and
Lua. Class-based languages distinguish classes from the objects that
belong to them, and in these languages inheritance is accomplished
within the class hierarchy. Object-based languages omit this
distinction, and instead allow objects to inherit directly from other
objects and to produce their own clone or child objects. In practice,
object-based languages often approximate classes by using certain
objects solely for inheritance. For this reason, and because of the
wider popularity of class-based languages, some have argued that
making classes an explicit part of a language is more convenient
\cite{Bruce}. One of our primary purposes is simplicity, however, so
ours will be an object-based semantics.

We will also draw an unconventional distinction between
object-\emph{oriented} languages, by which we mean those that
encourage a programming style centered around objects and inheritance,
and object-\emph{based} languages that merely use objects as the
fundamental unit of their semantics. Yalie is an object-\emph{based}
language, and it is not our intention to abandon the functional and
procedural paradigms traditional in Lisp languages. OOP will of course
be fairly natural in Yalie, but our goals of simplicity, consistency,
and flexibility should benefit any programming style.

\subsection*{Message Passing}
As a demonstration of the consistency possible with objects, we base
all of the semantics of Yalie on message passing. This is very
different from traditional Lisp semantics and requires some
explanation. For an example, suppose we wish to evaluate the
S-expression
\[ \texttt{(+ 1 2)}. \] That is a list object (i.e.\ a series of cons
objects with a nil object at the end) containing a symbol object and
two integer objects. Evaluation begins by calling the \eval\ method of
the list. As with all Lisp dialects, S-expressions represent function
calls, so the \eval\ method of a list calls the \eval\ method of its
first element, expecting to receive a function or special form object
of some kind. The \eval\ method of the \texttt{+} symbol returns the
binding of that symbol in the calling scope, which is indeed a
function. The list \eval\ then invokes the \call\ method of that
object, passing the remainder of the list as arguments, and finally
returns $3$.

Traditionally, S-expressions represented function calls because a
central evaluation loop interpreted them that way. Here they represent
function calls because their \eval\ method carries out a function
call. Note also that a function or form in Yalie is just an ordinary
object with a defined \call\ method. We will construct a few
predefined functions and forms in Yalie, and these will be ordinary
objects whose \call\ methods we define usefully.

Another key difference in this function is the way \texttt{+} is
defined, which is not immediately visible. Rather than being a
built-in operation that knows about integers, \texttt{+} simply
invokes a method of its arguments. This method is also named
\texttt{+}, though it resides in the integer method table rather than
in the lexical scope as the \texttt{+} function does. One of the
functions we will define is \msg, which allows the user to invoke
methods explicitly. Expressed using \msg, the S-expression we
considered above can be rewritten as
\[\texttt{(msg 1 + 2)}.\]
That is, adding $1$ to $2$ means sending the \texttt{+} message to the
object $1$ with the argument $2$. In full detail, the \eval\ method of
that list evaluates the symbol \msg, whose value is a special form
object with a \call\ method designed to pass messages and invoke
methods. When that \call\ method is invoked, it evaluates its first
argument, the $1$ object, and invokes the method of that first
argument named by the second argument, passing any further arguments
to that method.

Something to keep in mind as we continue is that anything defined as a
method can be invoked explicitly or even redefined by the user. Thus,
the first S-expression could be rewritten again as
\[ \texttt{(msg + call 1 2)}, \]
and the second could even be rewritten
\[ \texttt{(msg msg call 1 + 2)}. \] The latter is not particularly
useful, but it illustrates what is going on ``under the hood.'' We
will discuss the facilities for defining and redefining new methods in
later sections.

\subsection*{Semantic Machinery}
The semantics of our language will be built from several different
components. Persistent, often mutable objects will be the core of our
language, so evaluation will use both a scope and a store. A scope is
a map from names to positive integer values, which we call
``pointers.'' We denote scopes by the variable $\varphi$, with the
global scope---that is, the built-in scope in which program evaluation
begins---denoted by $\Phi$. A store is then a map from these pointers
to objects, and this indirection allows us to mutate objects by
modifying the store. We denote a store by the variable $\sigma$, and
the global store, analogous to the global scope, is denoted by
$\Sigma$. An extension to a scope or a store is denoted by the
expression $[\sigma|\text{key}\rightarrow\text{val}]$. We will
frequently refer to the pointers to certain built-in objects using
capitalized names like {\ptr ROOT}, the primary object at the top of
the inheritance hierarchy, or {\ptr INT}, the object from which all
integers inherit. The objects to which these pointers refer are then
written $\Sigma(\text{\ptr ROOT})$ and $\Sigma(\text{\ptr INT})$. The actual
values of these pointers are arbitrary, so long as they are constant
and unique. The only other way we will refer to pointer values is the
$\next(\sigma)$ function, whose value is the smallest pointer not
currently in the domain of $\sigma$. We will generally use the
variable $\omega$ to denote pointers, though we will also use the
variable $a$ to refer to arguments to functions and $e$ to refer to
the results of evaluation.

An object has four important properties. It has a parent object from
which it inherits method functions, a map of its own from names to
method functions, a scope of member elements, and a field for
underlying data such as an integer or a name. We will define objects
as ordered 4-tuples, written
\[ \lb p, \mu, \varphi, d \rb .\]
For example, the integer five would be represented as
\[ \lb \text{\ptr INT}, \mu_0, \varphi_0, 5 \rb, \]
where $\mu_0$ is the empty function map, and $\varphi_0$ is the empty
scope. Likewise, the symbol \texttt{foo} would be represented as
\[ \lb \text{\ptr SYMBOL}, \mu_0, \varphi_0, \text{``foo''} \rb. \] We
will frequently use the notation $\mu_{\sigma(\omega)}$ and
$\varphi_{\sigma(\omega)}$ to refer to the function map or scope
elements of the object $\sigma(\omega)$. Similarly, we will use
$p_{\sigma(\omega)}$ and $d_{\sigma(\omega)}$ to refer to the parent
pointer and underlying data element of $\sigma(\omega)$. Note that the
the root object does not have a parent, i.e.
$p_{\Sigma(\text{\subptr ROOT})} = \varnothing$.

We have already mentioned the function $\next(\sigma)$, and we will
introduce two more semantic functions here that we will need
below. The first is our function for looking up methods, using the
``message-passing'' terminology of Simula and Smalltalk. When a method
cannot be found in the method table of a given object, its parent is
queried recursively. Character strings representing method names are
denoted by the variable $m$.
\begin{multline*} \lookup(m, \sigma, \omega) = \\
\begin{cases}
  \varphi_{\sigma(\omega)} &\text{if } m \in
  \operatorname{Domain}(\varphi_{\sigma(\omega)}) \\
  \lookup(m,\sigma,p_{\sigma(\omega)})
  &\text{else if }p_{\sigma(\omega)}\neq \varnothing\\
  \mathit{undefined} & \text {otherwise}
  \end{cases}
\end{multline*}
In practice, these character strings will either be supplied
explicitly by a built-in method definition or extracted from the data
field of a symbol object.

The second function we need to define at the moment is the semantic
function for invoking methods. We mentioned the \msg\ function in the
preceding section, and this semantic function will eventually form the
core of that object's \call\ method, in addition to being used
explicitly by many other methods. The invocation of a method requires
the current store and scope as well as a pointer to the invoking
object and all the arguments of the method, the latter expressed as an
ordered tuple. Method functions will be defined so that the value of
an invocation is a 3-tuple containing the new store and scope and a
pointer to the object returned by the method.
\begin{multline*}
  \invoke( m, \sigma, \varphi, \lb a_1,\ldots a_n\rb) = \\
  (\lookup(m, \sigma, \omega))(\sigma,\varphi,\omega,
  \lb a_1,\ldots a_n \rb )
\end{multline*}
  
\section*{Syntax}

With the goal of unifying code and data, we will take a two-part
approach to specifying the semantics of our language. First, we will
describe the translation from syntax to literal objects. Then we will
define the methods available to those objects. Invocation of the
\eval\ methods of our code will be responsible for most of the work
done by a program, and ultimately our denotational semantic operator,
$[\![-]\!]$, will be the simple combination of the parse and invoke
operations with $\Sigma$ and $\Phi$.

\subsection*{Literal Objects}
Yalie contains only three literal objects: integers, symbols, and
lists. Integers are written as strings of decimal digits. Symbols are
written as any string of characters (other than those defined as
punctuation in this section) that does not denote an integer. Lists
are written as sequences of whitespace-separated literals enclosed by
matching parentheses. We define a parsing function that takes an
abstract syntax expression and an initial store, and returns a tuple
containing a pointer to the new object and the updated store.  An
integer $n$ is thus parsed as
\begin{multline*}
\parse(n,\sigma) =
\lb\next(\sigma),[\sigma|\operatorname{next}(\sigma) \rightarrow\right. \\
\left.\lb\text{\ptr INT}, \mu_0, \varphi_{\Sigma(\text{\subptr INT})}, n\rb]\rb,
\end{multline*}
and a symbol $s$ is parsed as
\begin{multline*}
  \parse(s,\sigma) =
  \lb\next(\sigma),[\sigma|\operatorname{next}(\sigma) \rightarrow\right. \\
\left.\lb\text{\ptr SYMBOL}, \mu_0, \varphi_{\Sigma(\text{\subptr SYMBOL})},
  s\rb]\rb.
\end{multline*}
Note that the parent of each new integer or symbol object is the
global integer or symbol object, respectively. These objects are
created with an empty method table, meaning that they inherit all of
their methods by default. They also copy the member scope of their
parent, which is empty by default unless modified by the user.

Finally, lists are parsed into ``cons'' objects, as is traditional for
Lisp languages. The underlying data field, $d$, of these cons objects
will be an ordered pair of the form $\lb a,b\rb$, and they will be
chained together to form linked lists terminated in a ``nil''
object. List parsing will be defined in two steps. First, the empty
list is parsed as
\begin{multline*}
  \parse(\texttt{()},\sigma) = \lb\next(\sigma),
  [\sigma|\operatorname{next}(\sigma) \rightarrow \right.\\
\left.\lb\text{\ptr NIL}, \mu_0, \varphi_{\Sigma(\text{\subptr NIL})}, \varnothing\rb]\rb.
\end{multline*}
This is similar to the integer and symbol parsing operations above,
though note that the data field of nil objects is ignored. List
parsing for nonempty lists can now be defined recursively.
\begin{multline*} \parse(\texttt{(a b \ldots\ z)},\sigma) = \lb
  \next(\sigma''),[\sigma'' \right. |\\\left.\operatorname{next}(\sigma'')
  \rightarrow\lb\text{\ptr CONS}, \mu_0,
  \varphi_{\Sigma(\text{\subptr CONS})},
  \lb F, R \rb \rb ] \rb
\end{multline*}
where
\begin{align*}
  \lb F, \sigma' \rb &= \parse( \texttt{a}, \sigma ) \\
  \lb R, \sigma'' \rb &= \parse( \texttt{(b \ldots\ z)}, \sigma')
\end{align*}
This expression can be slightly confusing. $F$ denotes the pointer to
the first parsed object in a list, and $\sigma'$ is the store after
parsing that object. $R$ then denotes the pointer to the rest of the
list, acquired recursively, and $\sigma''$ is the store after all that
parsing is done. The whole list is finally assembled by adding to
$\sigma''$ the cons cell at the head of the list.

As we mentioned above, we can now define the denotational semantic
operator for Yalie expressions.
\[ [\![-]\!]\phantom{,}\Sigma\phantom{,}\Phi = \invoke(\text{``eval''},
\Sigma', \Phi, \omega, \lb\rb),\] where $\lb \Sigma', \Phi, \omega\rb
= \parse({}-{},\Sigma)$.

\subsection*{Syntactic Sugar}
In addition to these literals, we define some extra translational
syntax for convenience. First we give a dot operator for message
passing, and second we will provide a quote operator to protect
objects from automatic evaluation.

As we mentioned above, message passing is invoked using the \msg\
special form, in the manner
\[\texttt{(msg obj message [args...])}.\]
We supply the dot operator to avoid writing that entire
S-expression for every method call. Without parentheses, \texttt{a.b}
translates as
\[\texttt{a.b}\rightarrow\texttt{(msg a b)}.\]
When placed after the first element of an S-expression, the dot
operator subsumes the rest of the S-expression as arguments. Thus
\texttt{(a.b c\ldots)}  translates as
\[\texttt{(a.b c\ldots)} \rightarrow \texttt{(msg a b c\ldots)}.\]
Finally, when there are multiple consecutive infix operations at the
front of an S-expression, we evaluate from left to right and allow the
final infix to capture the expression. Thus \texttt{(a.b.c d e)}
translates as
\[ \texttt{(a.b.c d e)} \rightarrow \texttt{(msg (msg a b) c d e)}.\]

Another global special form that we define is the \texttt{quote}
operator, which protects objects from evaluation. We use the grave
quote as a prefix operator that takes precedence over the dot, and we
translate \texttt{`a} as
\[ \texttt{`a} \rightarrow \texttt{(quote a)}.\]
Accompanying the quote syntax we provide unquote and splice syntax, in
the style of Common Lisp and Scheme. These translate as
\begin{align*}
  \texttt{,a} & \rightarrow \texttt{(unquote a)}\\
  \texttt{;a} & \rightarrow \texttt{(unquote-splice a)}.
\end{align*}
Note that \texttt{unquote} and \texttt{unquote-splice} are not defined
as separate operators but are rather ordinary symbols that the
\texttt{quote} operator itself parses. Note also that the semicolon is
used for splicing in Yalie, rather than for commenting, and it
replaces the comma-at operator used for splicing in other
Lisps. Comments in Yalie are denoted by a hash mark, as is common in
scripting languages.

\section*{Built-in Objects and Methods}

Yalie defines a number of objects that exist in the global scope and
store when any program begins. We have already encountered the
{\ptr ROOT}, {\ptr INT}, {\ptr SYMBOL}, {\ptr CONS}, and
{\ptr NIL} objects. Other generic parent objects include
{\ptr FUNCTION}, {\ptr FORM}, and their mutual parent,
{\ptr OPERATOR}. Predefined function and form objects, which inherit
from these, include {\ptr MSG} and {\ptr QUOTE}. Others we have
not yet encountered include {\ptr IF} and {\ptr WHILE}. By
convention, we give each such object in $\Sigma$ a corresponding
binding in $\Phi$.

The meat of our language is not this hierarchy itself but rather the
methods defined for these objects. Below we provide formal definitions
of many of the most important methods implemented in the Yalie
interpreter. We will define several methods inherited by every object
and also a few prominent methods outside the root object.

The \texttt{parent} method returns the parent of a given object, and
it is a good example with which to start. The definition reads
\[ \mu_{\Sigma(\text{\subptr ROOT})}(\text{``parent''})(\sigma,\varphi,\omega,
\lb\rb) = \lb [\sigma,\varphi,p_{\sigma(\omega)}] \rb. \] Recall that
$\mu_{\Sigma(\text{\subptr ROOT})}$ is the method table of the {\ptr ROOT}
object in the global store, $\Sigma$. This method does not modify the
store or the scope, so those are returned directly. As mentioned
above, $p_{\sigma(\omega)}$ refers to the $p$ element of the object
$\sigma(\omega)$, which is the pointer to the parent of the calling
object.

We can also introduce the default \eval\ method, which most objects
will inherit. This is just the identity method on the caller, so the
definition is even simpler.
\[ \mu_{\Sigma(\text{\subptr ROOT})}(\text{``eval''})(\sigma,\varphi,\omega,
\lb\rb) = \lb [\sigma,\varphi,\omega] \rb. \]

The next two methods we define are \texttt{copy} and
\texttt{child}. These methods are fundamental to an object-based
language. Apart from literal objects, copying is the simplest way to
produce a new object. A copied object shares the same parent as its
source, and it replicates its source's method table, member scope, and
underlying data. After copying the two objects are independent;
changing one does not affect the other. The copy method is defined as
\begin{multline*}
  \mu_{\Sigma(\text{\subptr ROOT})}(\text{``copy''})(\sigma,\varphi,\omega,
\lb\rb) \\ = \lb [\sigma|\next(\sigma)\rightarrow\sigma(\omega)],\varphi,
\next(\sigma)\rb.
\end{multline*}
The other essential way to create a new object is to spawn a child
object that inherits from a parent. Children also copy the member
scopes and underlying data of their parent, but their method table is
initially empty, and they inherit all their methods from the
parent. Thus any changes made to the methods of the parent will be
reflected in the child. The child method is defined as
\begin{multline*}
  \mu_{\Sigma(\text{\subptr ROOT})}(\text{``child''})(\sigma,\varphi,\omega,
  \lb\rb) \\ = \lb [\sigma|\next(\sigma)\rightarrow \lb \omega, \mu_0,
  \varphi_{\sigma(\omega)}, d_{\sigma(\omega)}\rb],\right.\\\left.\varphi,
  \next(\sigma)\rb.
\end{multline*}

Another pair of important methods is the \texttt{get} and \texttt{set}
methods, which query and modify member values. These are not used by
any other built-in functions or methods, but they are an important
facility for user-defined objects. The \texttt{get} method is the
simpler of the two, and it is also the first method we have defined so
far that takes an argument.
\[ \mu_{\Sigma(\text{\subptr ROOT})}(\text{``get''})(\sigma,\varphi,\omega,
\lb a_1\rb) = \lb \sigma, \varphi,
\varphi_{\sigma(\omega)}(d_{\sigma(a_1)})\rb.\] That is, the
\texttt{get} method receives a symbol, $a_1$, and references its data
element in the member scope of the caller. The \texttt{let} and
\texttt{set} methods take two elements, and these are the first
methods we have seen so far that will evaluate an argument. The first
argument is a symbol giving the member name, and the second is
evaluated to give the new value of the member and the return value of
the method call. The \texttt{let} method is used only when the member
variable is currently bound, and \texttt{set} is used only to modify
an existing binding. Thus, in the case where $d_{\sigma(a_1)}$ is not
in the domain of $\varphi_{\sigma(\omega)}$, \texttt{let} is defined
as
\begin{multline*}
  \mu_{\Sigma(\text{\subptr ROOT})}(\text{``let''})(\sigma,\varphi,\omega,
  \lb a_1,a_2\rb) =\\ \lb [\sigma'|\omega\rightarrow \lb p_{\sigma(\omega)},
  \mu_{\sigma(\omega)},[\varphi_{\sigma(\omega)}|d_{\sigma(a_1)}\rightarrow e_1],
  d_{\sigma(\omega)}\rb],\right.\\\left.\varphi', e_1\rb.
\end{multline*}
where $\lb \sigma',\varphi',e_1 \rb = \invoke(\text{``eval''},\sigma,
\varphi, a_2, \lb\rb)$. In the case where $d_{\sigma(a_1)}$ is in the
domain of $\varphi_{\sigma(\omega)}$, \texttt{let} is
undefined. Likewise, \texttt{set} is defined only in that case, and
its definition takes the same form as \texttt{let} immediately
above. These two methods are defined this way in order to separate the
creation of new bindings from the modification of existing ones. This
is helpful for functional programming, and it also causes many bugs to
raise an exception instead of passing silently.

The final method of the root object that we define here is
\texttt{dup}, which serves in place of the ``super'' keyword from
languages like C++. When a child object redefines an inherited method
but wishes to invoke the inherited version, it must first duplicate
that original method to another binding. The \texttt{dup} method thus
takes two arguments, a method name and a name for the new
binding. Note that even if the original binding is inherited, the new
binding will be local to the calling object.
\begin{multline*}
  \mu_{\Sigma(\text{\subptr ROOT})}(\text{``dup''})(\sigma,\varphi,\omega,
  \lb a_1,a_2\rb) =\\ \lb [\sigma|\omega\rightarrow \lb
  p_{\sigma(\omega)}, [\mu_{\sigma(\omega)}|d_{\sigma(a_2)}\rightarrow
  \lookup(d_{\sigma(a_1)},\sigma,\omega)],\right.\right.\\\left.\left.
  \varphi_{\sigma(\omega)},
  d_{\sigma(\omega)}\rb],\varphi, \omega\rb.
\end{multline*}

One critical method outside of the root object is the \eval\ method of
symbols. Rather than evaluating to themselves, as most objects do,
symbols evaluate to their binding in the current scope.
\[  \mu_{\Sigma(\text{\subptr SYMBOL})}(\text{``eval''})(\sigma,\varphi,\omega,
\lb a_1\rb) = \lb \sigma, \varphi, \varphi(d_{\sigma(\omega)})\rb.\]

The other nontrivial \eval\ method is that of cons lists. As described
in a previous section, the \eval\ method of a list evaluates its first
element and then invokes the \call\ method of that value with the rest
of the list passed as arguments. We denote this as
\begin{multline*}
\mu_{\Sigma(\text{\subptr CONS})}(\text{``eval''})(\sigma,\varphi,\omega,
\lb\rb) = \\\invoke(\text{``call''},\sigma',\varphi',e_1,\lb a_2,\ldots
a_n\rb).
\end{multline*}
where 
\[ \lb \sigma',\varphi',e_1\rb =
\invoke(\text{``eval''},\sigma,\varphi,a_1,\lb\rb) \]
and $\lb a_1,a_2,\ldots a_n\rb$ is the tuple representing the
contents of $\sigma(\omega)$.

The final method we define here is the critical \call\ method of the
\msg\ object. Recall that the \msg\ form allows the user to invoke
methods explicitly, and it is the \call\ method of that form object
that exposes this functionality
\begin{multline*}
  \mu_{\Sigma(\text{\subptr MSG})}(\text{``call''})(\sigma,\varphi,\omega,
  \lb a_1,\ldots a_n \rb) = \\\invoke( d_{\sigma'(a_2)}, \sigma', \varphi', e_1,
  \lb a_3,\ldots a_n \rb),
\end{multline*}
where $\lb \sigma', \varphi', e_1\rb =
\invoke(\text{``eval''},\sigma,\varphi,a_1,\lb\rb)$.

\section*{Departures}
Today Lisp is over fifty years old, and Common Lisp is already half
that age. Aside from adding wholly new features, there is much room
for improvement in the traditional syntax of the language. Some common
names can be helpfully shortened (\texttt{fn} instead of
\texttt{lambda}, \texttt{ls} instead of \texttt{list}), and there are
several opportunities to reduce the sheer number of parentheses that a
programmer needs to type \cite{Graham}. Here we explain four such
opportunities that we have included in Yalie.

First, the functionality of the \texttt{cond} expression is
incorporated into \texttt{if} without changing the basic structure of
an \texttt{if} call. In particular, \texttt{if} can be made to take an
arbitrary number of test-consequence pairs, with an optional unpaired
expression interpreted as an alternative. For example:
\begin{quote}
\begin{verbatim}
(if test1 a
    test2 b
    test3 c
          d)
\end{verbatim}
\end{quote}

Second, parentheses inside the bindings of a \texttt{let} expression
are simply dropped. This gives the cleaner syntax:
\begin{quote}
\begin{verbatim}
(let (a 1
      b 2)
  (+ a b))
\end{verbatim}
\end{quote}
Yalie also extends the meaning of \texttt{let} in a different way. A
\texttt{let} expression with a single binding and no body creates a
local binding in the calling scope that persists until the end of that
scope. This allows the programmer to create a local variable without
adding a level of nesting and indentation, which can greatly improve
readability. When doing this, a further pair of parentheses is
omitted. Thus, the following is valid:
\begin{quote}
\begin{verbatim}
(let a 1)
(+ a 2)
\end{verbatim}
\end{quote}
As implemented in Yalie, \texttt{let} can create a new binding in this
way but cannot modify an existing one. (The \texttt{set} function
exists for that.) The purpose of the distinction is to separate
variable declaration from variable modification, so that typographical
errors in variable assignments will raise an exception instead of
silently creating a new variable. Yalie also follows the convention
that any non-functional operations be marked with ``set'' or ``!''.

Finally, the functionality of the \texttt{not} operator is extended to
include multiple arguments. When receiving more than one argument, not
interprets all its arguments as a function call and returns that
call's negation. For instance, the following returns a true value:
\begin{quote}
\begin{verbatim}
(not = 0 1)
\end{verbatim}
\end{quote}
In many common cases, this both increases readability and saves the
user two parentheses.

\section*{Objects: The Ultimate Lambda}
As both an illustrative example and a demonstration of the flexibility
of the object system, we detail the creation of a \texttt{lambda}
operator. Yalie has such an operator built in for convenience (under
the name \texttt{fn}), but we show how it can be defined within the
language. As a second example, we will also create a factorial method
for the integers.

We will need two methods that we did not formally define above,
\texttt{def} and \texttt{deform}. These methods allow the user to
define new methods and method forms in a given object. Recall that the
difference between a function and a form (or ``macro'') is that a
function implicitly evaluates its arguments while a form implicitly
evaluates its return. Methods and method forms work in the same way,
except that they are invoked by message passing. The syntax of the
\texttt{def} and \texttt{deform} methods is identical to the syntax of
the \texttt{define} operator in Scheme, and the return value of both
methods is the calling object.

The definition of \texttt{lambda} thus reads
\begin{quote}
\begin{verbatim}
(let lambda Form.child)
(lambda.deform (call args (rest body))
  `(let (ret Function.child)
     (ret.def (call ;args)
       ;body)))
\end{verbatim}
\end{quote}
The first expression creates a child object from the object that is
the parent of all forms and binds it to the name ``lambda''. We could
have used any object as the parent, but this way the new operator will
inherit whatever methods other forms inherit. The second expression
defines a \call\ method for the newly created object. Recall that
\call\ methods are invoked when S-expressions are evaluated, and so
this method will contain the functionality of \texttt{lambda}. The
method is a form, so its value is Yalie code to be executed at the end
of the call. This code can be confusing, because it is creating a
second child object---from the parent of all functions, this
time---with its own call method. This new object is the anonymous
function that \texttt{lambda} returns. Note that the arguments and the
function body are just spliced into the call to the \texttt{def}
method of the new object.

For a final example, the following code would define a factorial
method named ``!'' for all integers. Note that methods and method
forms implicitly bind the variable \texttt{self} to the calling
object.
\begin{quote}
\begin{verbatim}
(Int.def (!)
  (if (<= self 0)
      1
      (* self (- self 1).!)))
\end{verbatim}
\end{quote}

\section*{Conclusions}
Several different interpreters were created at different stages in
this project, but the ``call'' and ``eval'' semantics as described in
this paper were only conceived for the final version. The ease of
coding these semantics relative to the more standard approach (using a
central eval loop) was striking, both in reduced programming time and
in reduced debugging time. These semantics are also far easier to
modify than any previous.

The language is still very small, so some of the benefits of the
object-based approach are not yet apparent. One visible benefit is
that, despite having gutted the entire language to allow the
ubiquitous use of objects, the only change the global namespace is the
addition of the \msg\ function. All other object facilities are
confined within the method spaces. If we were to further extend the
language---with strings and file handles for example---we would see
the same benefits repeated, with new functionality mostly confined to
method spaces. Not only does this approach keep the global namespace
free of clutter, it also provides helpful documentation in the form of
method lists.

We have demonstrated the flexibility of the object-based approach, and
the simplicity of the semantics has already made itself felt during
the implementation process. We look forward to finding new ways of
leveraging the object abstraction, both by itself and in conjunction
with Lisp's macro system.

\section*{Acknowledgements}
Thanks to Paul Hudak for advising this project and to Tristyn Bloom
for helping to proofread it.

\begin{thebibliography}{9}
\bibitem{Abadi} M. Abadi and L. Cardelli. \textit{A Theory of Objects.} New
  York: Springer, 1996.

\bibitem{Bruce} K. B. Bruce. \textit{Foundations of Object-Oriented
    Languages.} Cambridge, Massachusetts: MIT Press, 2002.

\bibitem{Graham} P. Graham. \textit{Arc at 3 Weeks.} November
  2001. Web. 8 May 2009.\\ $<$http://www.paulgraham.com/arcll1.html$>$.
\end{thebibliography}

\section*{Appendix: README}
This appendix contains the text of the README file that accompanies
the Yalie interpreter.

\verbinput{README}

\section*{Appendix: builtins.py}
This appendix contains the text of the file ``builtins.py''. This file
defines any functions or forms not defined in the Python code.

\verbinput{builtins.y}

\end{document}
