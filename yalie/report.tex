\documentclass[twocolumn]{article}
\usepackage{amsmath,graphicx,amsfonts,amssymb}
\usepackage{sverb}
\title{Yet Another Lisp Interpreting Experiment}
\author{John O'Connor}
\date{}

\begin{document}

\newcommand{\next}{\operatorname{next}}
\newcommand{\invoke}{\operatorname{invoke}}
\newcommand{\lookup}{\operatorname{lookup}}
\newcommand{\wrap}{\operatorname{wrap}}
\newcommand{\parse}{\operatorname{parse}}

\newcommand{\eval}{\texttt{eval}}
\newcommand{\call}{\texttt{call}}
\newcommand{\msg}{\texttt{msg}}

\newcommand{\lb}{\left<}
\newcommand{\rb}{\right>}

\maketitle

\section*{Introduction}
One of the historical attractions of the Lisp family of programming
languages has been their flexibility. Lisp was one of the first
languages to include dynamic typing, and Lisp macros allow the
programmer to create new binding forms and control structures. This
flexibility is one of the reasons for Lisp's popularity in the AI
community. Programmers can implement domain-specific mini-languages
without losing the infrastructure of a full language implementation.

Another strength of Lisp is its elegance. The S-expression syntax
allows Lisp to treat lists as code. Thus Lisp macros, by constructing
and returning lists of symbols, actually return instructions to be
executed. This is one of the more confusing aspects of Lisp for
newcomers, to be sure, but it also simplifies the language in an
important sense. Where most languages have code and data, Lisp has
only data. In the long run, fewer ``moving parts'' means fewer
distinct concepts that a programmer needs to keep in mind to
understand his language.

More recent developments, however, have seen Lisp fall behind. In
particular, the Smalltalk language demonstrated that it is possible to
treat everything in a language as an ``object.'' The widely-used
Python and Ruby languages have adopted many concepts from Smalltalk
with great success. Several object-oriented variants of Lisp have been
developed, including the Common Lisp Object System, but these have not
achieved nearly the same popularity. We wish to suggest that one of
the failings of various Lisp object systems is that they are built for
the wrong reasons.

Through object-orientation, Smalltalk was able to achieve greater
flexibility and greater simplicity. These goals are essentially
orthogonal to the goal of facilitating an object-oriented programming
(OOP) style. Lisp object systems have attempted the latter, and as a
result they have generally made their languages more complicated and
less consistent. We believe that objects can greatly enhance Lisp's
core strengths, but only if these concepts are introduced consistently
throughout the entire language.

This is the intention of Yet Another Lisp Interpreting Experiment (or,
``Yalie''). Our goal is to demonstrate a Lisp variant in which
everything is an object and all function calls are based on message
passing. In doing this, we hope to make the language less complicated,
rather than more so. An interactive interpreter for Yalie, written in
Python, accompanies this paper. What follows is a formal description
of the language implemented in that interpreter. For a more practical
description with examples, please see the accompanying README file,
reprinted here in the appendix. This paper assumes the reader is
familiar with a modern Lisp dialect such as Scheme or Common Lisp.

\section*{Concepts}
\subsection*{Object-based Languages}
Broadly speaking, there are two major categories of object-oriented
languages \cite{Abadi}. The most common are the ``class-based''
languages, including C++, Java, and Smalltalk. The other category is
``object-based'' or ``prototype-based'' languages, like JavaScript and
Lua. Class-based languages distinguish classes from the objects that
belong to them, and in these languages inheritance is accomplished
within the class hierarchy. Object-based languages omit this
distinction, and instead allow objects to inherit directly from other
objects and to produce their own clone or child objects. In practice,
object-based languages often approximate classes by using certain
objects solely for inheritance, and for this reason---and because of
the wider popularity of class-based languages---some have argued that
making classes an explicit part of the language is more
convenient \cite{Bruce}. Our purpose here is simplicity, however, so
ours will be an object-based semantics.

We will also draw an unconventional distinction between
object-\emph{oriented} languages, by which we mean those that
encourage a programming style centered around objects and inheritance,
and object-\emph{based} languages, which merely use objects as the
fundamental unit of their semantics. Yalie is an object-\emph{based}
language, and our intention is to replicate the functional and
procedural paradigms traditional in Lisp languages. Obviously, an
object-based semantics will make OOP fairly natural in Yalie, but our
primary goals of simplicity, consistency, and flexibility should
benefit any programming style.

\subsection*{Message Passing}
As a demonstration of the consistency possible with objects, all of
the semantics of our language aside from literal syntax is based on
message passing. This is very different from traditional Lisp
semantics and requires some explanation. For an example, suppose we
wish to evaluate the S-expression
\[ \texttt{(+ 1 2)}. \] That is a list object (a series of cons
objects, in fact) containing a symbol object and two integer
objects. Evaluation begins by calling the \eval\ method of the list. As
with all Lisp dialects, S-expressions represent function calls, so the
\eval\ method of a list calls the \eval\ method of its first element,
expecting a function or special form object of some kind. The \eval\
method of the \texttt{+} symbol returns the binding of that symbol in
the calling scope, which is indeed a function. The list \eval\ then
invokes the \call\ method of that object, passing the remainder of the
list as arguments, and finally returns $3$.

Traditionally, S-expressions represented function calls because a
central evaluation loop interpreted them that way. Here they represent
function calls because their \eval\ method carries out a function
call. Note also that a functions or form in Yalie is just an ordinary
objects with a defined \call\ method. We will construct a few
predefined functions and forms in Yalie, and these will be ordinary
objects whose \call\ methods we define usefully.

Another key difference in this function is the way \texttt{+} is
defined, which is not immediately visible. Rather than being a
built-in operation that knows about integers, \texttt{+} simply calls
invokes a method of its arguments. This method is also named
\texttt{+}, though it resides in method tables rather than the lexical
scope as the \texttt{+} function does. One of the functions we will
define is \msg, which allows the user to invoke methods
explicitly. Expressed using \msg, the S-expression we considered above
can be rewritten as
\[\texttt{(msg 1 + 2)}.\]
That is, adding $1$ to $2$ means sending the \texttt{+} message to the
object $1$ with the argument $2$. In full detail, the \eval\ method of
that list evaluates the symbol \msg, whose value is a special form
object with a \call\ method designed to pass messages and invoke
methods. When that \call\ method is invoked, it evaluates its first
argument, the $1$ object, and invokes the method of that first
argument named by the second argument, passing any further arguments
to that method.

Something to keep in mind as we continue is that anything defined as a
method can be invoked explicitly or even redefined by the user. Thus,
the first S-expression could be rewritten again as
\[ \texttt{(msg + call 1 2)}, \]
and the second could even be rewritten
\[ \texttt{(msg msg call 1 + 2)}. \] The latter is not particularly
useful, but it illustrates what is going on ``under the hood.'' We
will discuss the facilities for defining and redefining new methods in
later sections.

\subsection*{Semantic Machinery}
The semantics of our language will be built from several different
components. Persistent, often mutable objects will be the core of our
language, so evaluation will use both a scope and a store. A scope is
a map from names to positive integer values. We will refer to these
integers suggestively as pointers. We denote scopes by the variable
$\varphi$, with the global scope---that is, the built-in scope in which
program evaluation begins---denoted by $\Phi$. A store is then a map
from these pointers to objects, and this indirection allows us to
mutate objects by modifying the store. We denote a store by the
variable $\sigma$, and the global store, analogous to the global
scope, is denoted by $\Sigma$. An extension to a scope or a store is
denoted by the expression
$[\sigma|\text{key}\rightarrow\text{val}]$. We will frequently refer to
the pointers to certain built-in objects using capitalized names like
\textsf{ROOT}, the primary object at the top of the inheritance
hierarchy, or \textsf{INT}, the object from which all integers
inherit. The objects to which these pointers refer are then written
$\Sigma(\mathsf{ROOT})$ and $\Sigma(\mathsf{INT})$. The actual values
of these pointers are arbitrary, so long as they are constant and
unique. The only other way we will refer to pointer values is the
$\next(\sigma)$ function, whose value is the smallest pointer not
currently in the domain of $\sigma$. We will generally use the
variable $\omega$ to denote pointers, though we will also use the
variable $a$ to refer to arguments to functions and $e$ to refer to
the results of evaluation.

An object has four important properties. It has a parent object from
which it inherits method functions, a map of its own from names to
method functions, a scope of member elements, and a field for
underlying data such as an integer or a name. We will define objects
as ordered 4-tuples, written
\[ \lb p, \mu, \varphi, d \rb .\]
For example, the integer five would be represented as
\[ \lb \mathsf{INT}, \mu_0, \varphi_0, 5 \rb, \]
where $\mu_0$ is the empty function map, and $\varphi_0$ is the empty
scope. Likewise, the symbol \texttt{foo} would be represented as
\[ \lb \mathsf{SYMBOL}, \mu_0, \varphi_0, \text{``foo''} \rb. \] We
will frequently use the notation $\mu_{\sigma(\omega)}$ and
$\varphi_{\sigma(\omega)}$ to refer to the function map or scope
elements of the object $\sigma(\omega)$. Similarly, we will use
$p_{\sigma(\omega)}$ and $d_{\sigma(\omega)}$ to refer to the parent
pointer and underlying data element of $\sigma(\omega)$. Note that the
the root object does not have a parent, i.e.
$p_{\Sigma(\mathsf{ROOT})} = \varnothing$.

We have already mentioned the function $\next(\sigma)$, but we should
like to introduce two more semantic function here that we will use
later. The first is our function for looking up methods, using the
``message-passing'' terminology of Simula and Smalltalk. When a method
cannot be found in the method table of a given object, it's parent is
queried recursively. Character strings representing method names are
denoted by the variable $m$.
\begin{multline*} \lookup(m, \sigma, \omega) = \\
\begin{cases}
  \varphi_{\sigma(\omega)} &\text{if } m \in
  \operatorname{Domain}(\varphi_{\sigma(\omega)}) \\
  \lookup(m,\sigma,p_{\sigma(\omega)})
  &\text{else if }p_{\sigma(\omega)}\neq \varnothing\\
  \mathit{undefined} & \text {otherwise}
  \end{cases}
\end{multline*}
In practice, these character strings will either be supplied
explicitly by a built-in method definition or extracted from the data
field of a symbol object.

The second function we need to define at the moment is the semantic
function for invoking methods. We mentioned the \msg\ function in
the preceding section, and this semantic function will eventually form
the core of that object's \call\ method, in addition to being used
explicitly by many other methods. The invocation of a method requires
the current store and scope as well as pointers to invoking object and
all the arguments of the method, the latter expressed as an ordered
tuple. Method functions will be defined so that the value of an
invocation is a 3-tuple containing the new store and scope and a
pointer to the object returned by the method.
\begin{multline*}
  \invoke( m, \sigma, \varphi, \lb a_1,\ldots a_n\rb) = \\
  (\lookup(m, \sigma, \omega))(\sigma,\varphi,\omega,
  \lb a_1,\ldots a_n \rb )
\end{multline*}
  
\section*{Syntax}

With the goal of unifying code and data, we will take a two-part
approach to specifying the semantics of our language. First, we will
describe the translation from syntax to literal objects. Then we will
define the methods available to those objects. Invocation of the
\eval\ methods of our code will be responsible for most of the work
done by a program, and ultimately our denotational semantic operator,
$[\![-]\!]$, will be the simple combination of the parse and invoke
operations with $\Sigma$ and $\Phi$.

\subsection*{Literal Objects}
Yalie contains only three literal objects: integers, symbols, and
lists. Integers are written as strings of decimal digits. Symbols are
written as any string of characters (other than those defined as
punctuation in this section) that is not an integer. Lists are written
as a sequence of whitespace-separated literals enclosed by matching
parentheses. We define a parsing function that takes as arguments an
abstract syntax expression and an initial store, and returns a tuple
containing a pointer to the new object and the updated store.
An integer $n$ is thus parsed as
\begin{multline*}
\parse(n,\sigma) =
\lb\next(\sigma),[\sigma|\operatorname{next}(\sigma) \rightarrow\right. \\
\left.\lb\mathsf{INT}, \mu_0, \varphi_{\Sigma(\mathsf{INT})}, n\rb]\rb,
\end{multline*}
and a symbol $s$ is parsed as
\begin{multline*}
  \parse(s,\sigma) =
  \lb\next(\sigma),[\sigma|\operatorname{next}(\sigma) \rightarrow\right. \\
\left.\lb\mathsf{SYMBOL}, \mu_0, \varphi_{\Sigma(\mathsf{SYMBOL})},
  s\rb]\rb.
\end{multline*}
Note that the parent of each new integer or symbol object is the
global integer or symbol object, respectively. These objects are
created with an empty method table, meaning that they inherit all of
their methods by default. They also copy the member scope of their
parent, which is empty by default unless modified by the user.

Finally, lists are parsed into ``cons'' objects, as is traditional for
Lisp languages. The underlying data field, $d$, of these cons objects
will be an ordered pair of the form $\lb a,b\rb$, and they will be
chained together to form linked lists terminated in a ``nil''
object. List parsing will be defined in two steps. First, the empty
list is parsed as
\begin{multline*}
  \parse(\texttt{()},\sigma) = \lb\next(\sigma),
  [\sigma|\operatorname{next}(\sigma) \rightarrow \right.\\
\left.\lb\mathsf{NIL}, \mu_0, \varphi_{\Sigma(\mathsf{NIL})}, \varnothing\rb]\rb.
\end{multline*}
This is similar to the integer and symbol parsing operations above,
though note that the data field of nil objects is ignored. List
parsing for nonempty lists can now be defined recursively.
\begin{multline*} \parse(\texttt{(a b \ldots\ z)},\sigma) = \lb
  \next(\sigma''),[\sigma'' \right. |\\\left.\operatorname{next}(\sigma'')
  \rightarrow\lb\mathsf{CONS}, \mu_0,
  \varphi_{\Sigma(\mathsf{CONS})},
  \lb F, R \rb \rb ] \rb
\end{multline*}
where
\begin{align*}
  \lb F, \sigma' \rb &= \parse( \texttt{a}, \sigma ) \\
  \lb R, \sigma'' \rb &= \parse( \texttt{(b \ldots\ z)}, \sigma')
\end{align*}
This expression can be slightly confusing. $F$ denotes the pointer to
the first parsed object in a list, and $\sigma'$ is the store after
parsing that object. $R$ then denotes the pointer to the rest of the
list, acquired recursively, and $\sigma''$ is the store after all that
parsing is done. The whole list is finally assembled by adding to
$\sigma''$ the cons cell at the head of the list.

As we mentioned above, we can now define the denotational semantic
operator for Yalie expressions.
\[ [\![-]\!]\phantom{,}\Sigma\phantom{,}\Phi = \invoke(\text{``eval''},
\Sigma', \Phi, \omega, \lb\rb),\] where $\lb \Sigma', \Phi, \omega\rb
= \parse({}-{},\Sigma)$.

\subsection*{Syntactic Sugar}
In addition to these literals, we define some extra translational
syntax for convenience. First we give a dot operator for message
passing, and second we will provide a quote operator to protect
objects from automatic evaluation.

As we mentioned above, message passing is invoked using the \msg\
special form, in the manner
\[\texttt{(msg obj message [args...])}.\]
We supply the dot operator to avoid writing that entire
S-expression for every method call. Without parentheses, \texttt{a.b}
translates as
\[\texttt{a.b}\rightarrow\texttt{(msg a b)}.\]
When placed after the first element of an S-expression, the dot
operator subsumes the rest of the S-expression as arguments. Thus
\texttt{(a.b c\ldots)}  translates as
\[\texttt{(a.b c\ldots)} \rightarrow \texttt{(msg a b c\ldots)}.\]
Finally, when there are multiple consecutive infix operations at the
front of an S-expression, we evaluate from left to right and allow the
final infix to capture the expression. Thus \texttt{(a.b.c d e)}
translates as
\[ \texttt{(a.b.c d e)} \rightarrow \texttt{(msg (msg a b) c d e)}.\]

Another global special form that we define is the \texttt{quote}
operator, which protects objects from evaluation. We define the
accompanying grave quote as a prefix operator that takes precedence
over the dot, and we translate \texttt{`a} as
\[ \texttt{`a} \rightarrow \texttt{(quote a)}.\]
Accompanying the quote syntax we provide unquote and splice syntax, in
the manner of Common Lisp and Scheme. These translate as
\begin{align*}
  \texttt{,a} & \rightarrow \texttt{(unquote a)}\\
  \texttt{;a} & \rightarrow \texttt{(unquote-splice a)}.
\end{align*}
Note that \texttt{unquote} and \texttt{unquote-splice} are not defined
as separate operators but are rather ordinary symbols that the
\texttt{quote} operator looks for and handles itself. Note also that
the semicolon is used for splicing in Yalie, instead of the comma-at
operator used in other Lisps. Comments in Yalie are denoted by a hash
mark, as is common in scripting languages.

\section*{Built-in Objects and Methods}

Yalie defines a number of objects that exist in the global scope and
store when any program begins. We have already encountered the
\textsf{ROOT}, \textsf{INT}, \textsf{SYMBOL}, \textsf{CONS}, and
\textsf{NIL} objects. Other generic parent objects include
\textsf{FUNCTION}, \textsf{FORM}, and their mutual parent,
\textsf{OPERATOR}. Predefined function and form objects, which inherit
from these, include \textsf{MSG} and \textsf{QUOTE}. Others we have
not yet encountered include \textsf{IF} and \textsf{WHILE}. By
convention, we give each such object in $\Sigma$ a corresponding
binding in $\Phi$.

The meat of our language is not this hierarchy itself but rather the
methods defined for these objects. Below we provide formal definitions
of many of the most important methods implemented in the Yalie
interpreter. We will begin with several methods inherited by every
object and add to that description several important methods outside
the root object.

The \texttt{parent} method returns the parent of a given object, and
it is a good example with which to start. The definition reads
\[ \mu_{\Sigma(\mathsf{ROOT})}(\text{``parent''})(\sigma,\varphi,\omega,
\lb\rb) = \lb [\sigma,\varphi,p_{\sigma(\omega)}] \rb. \] Recall that
$\mu_{\Sigma(\mathsf{ROOT})}$ is the method table of the \textsf{ROOT}
object in the global store, $\Sigma$. This method does not modify the
store or the scope, so those are returned directly. As mentioned
above, $p_{\sigma(\omega)}$ refers to the $p$ element of the object
$\sigma(\omega)$, which is the pointer to the parent of the calling
object.

We can also introduce the default \eval\ method, which most objects
will inherit. This is just the identity method on the caller, so the
definition is even simpler.
\[ \mu_{\Sigma(\mathsf{ROOT})}(\text{``eval''})(\sigma,\varphi,\omega,
\lb\rb) = \lb [\sigma,\varphi,\omega] \rb. \]

The next two methods we define are \texttt{copy} and
\texttt{child}. These methods are fundamental to an object-based
language. Apart from literal objects, copying is the simplest way to
produce a new object. A copied object shares the same parent as its
source, and it replicates its source's the method table, member scope,
and underlying data. After copying the two objects are independent;
changing one does not affect the other. The copy method is defined as
\begin{multline*}
  \mu_{\Sigma(\mathsf{ROOT})}(\text{``copy''})(\sigma,\varphi,\omega,
\lb\rb) \\ = \lb [\sigma|\next(\sigma)\rightarrow\sigma(\omega)],\varphi,
\next(\sigma)\rb.
\end{multline*}
The other essential way to create a new object is to spawn a child
object that inherits from a parent. Children also copy the member
scopes and underlying data of their parent, but their method table is
initially empty, and they inherit all their methods from the
parent. Thus any changes made to the methods of the parent will be
reflected in the child. The child method is defined as
\begin{multline*}
  \mu_{\Sigma(\mathsf{ROOT})}(\text{``child''})(\sigma,\varphi,\omega,
  \lb\rb) \\ = \lb [\sigma|\next(\sigma)\rightarrow \lb \omega, \mu_0,
  \varphi_{\sigma(\omega)}, d_{\sigma(\omega)}\rb],\right.\\\left.\varphi,
  \next(\sigma)\rb.
\end{multline*}

Another pair of important methods is the \texttt{get} and \texttt{set}
methods, which query and modify member values. These are not used by
any other built-in functions or methods, but they are an important
facility for user-defined objects. The \texttt{get} method is the
simpler of the two, and it is also the first method we have defined so
far that takes an argument.
\[ \mu_{\Sigma(\mathsf{ROOT})}(\text{``get''})(\sigma,\varphi,\omega,
\lb a_1\rb) = \lb \sigma, \varphi,
\varphi_{\sigma(\omega)}(d_{\sigma(a_1)})\rb.\] That is, the
\texttt{get} method receives a symbol, $a_1$, and references its data
element in the member scope of the caller. The \texttt{set} method
takes two elements, and it is the first method so far that will
evaluate an argument. The first argument is a symbol giving the member
name, and the second is evaluated to give the new value of the member
and the return value of \texttt{set}.
\begin{multline*}
  \mu_{\Sigma(\mathsf{ROOT})}(\text{``set''})(\sigma,\varphi,\omega,
  \lb a_1,a_2\rb) =\\ \lb [\sigma'|\omega\rightarrow \lb p_{\sigma(\omega)},
  \mu_{\sigma(\omega)},[\varphi_{\sigma(\omega)}|d_{\sigma(a_1)}\rightarrow e_1],
  d_{\sigma(\omega)}\rb],\right.\\\left.\varphi', e_1\rb.
\end{multline*}
where $\lb \sigma',\varphi',e_1 \rb = \invoke(\text{``eval''},\sigma,
\varphi, a_2, \lb\rb)$.

The final method of the root object that we define here is
\texttt{dup}, which serves in place of the ``super'' keyword from
languages like C++. When a child object redefines an inherited method
but wishes to invoke the inherited version, it must first duplicate
that original method to another binding. The \texttt{dup} method thus
takes two arguments, a method name and a name for the new
binding. Note that even if the original binding is inherited, the new
binding will be local to the calling object.
\begin{multline*}
  \mu_{\Sigma(\mathsf{ROOT})}(\text{``dup''})(\sigma,\varphi,\omega,
  \lb a_1,a_2\rb) =\\ \lb [\sigma|\omega\rightarrow \lb
  p_{\sigma(\omega)}, [\mu_{\sigma(\omega)}|d_{\sigma(a_2)}\rightarrow
  \lookup(d_{\sigma(a_1)},\sigma,\omega)],\right.\right.\\\left.\left.
  \varphi_{\sigma(\omega)},
  d_{\sigma(\omega)}\rb],\varphi, \omega\rb.
\end{multline*}

One critical method outside of the root object is the \eval\ method of
symbols. Rather than evaluating to themselves, as most objects do,
symbols evaluate to their binding in the current scope.
\[  \mu_{\Sigma(\mathsf{SYMBOL})}(\text{``eval''})(\sigma,\varphi,\omega,
\lb a_1\rb) = \lb \sigma, \varphi, \varphi(d_{\sigma(\omega)})\rb.\]

The other nontrivial \eval\ method is that of cons lists. As described
in a previous section, the \eval\ method of a list evaluates its first
element and then invokes the \call\ method of that value with the rest
of the list passed as arguments. We denote this as
\begin{multline*}
\mu_{\Sigma(\mathsf{CONS})}(\text{``eval''})(\sigma,\varphi,\omega,
\lb\rb) = \\\invoke(\text{``call''},\sigma',\varphi',e_1,\lb a_2,\ldots
a_n\rb).
\end{multline*}
where 
\[ \lb \sigma',\varphi',e_1\rb =
\invoke(\text{``eval''},\sigma,\varphi,a_1,\lb\rb) \]
and $\lb a_1,a_2,\ldots a_n\rb$ is the tuple representing the
contents of $\sigma(\omega)$.

The final method we define here is the critical \call\ method of the
\msg\ object. Recall that the \msg\ form allows the user to invoke
methods explicitly, and it is the \call\ method of that form object
that exposes this functionality
\begin{multline*}
  \mu_{\Sigma(\mathsf{MSG})}(\text{``call''})(\sigma,\varphi,\omega,
  \lb a_1,\ldots a_n \rb) = \\\invoke( d_{\sigma'(a_2)}, \sigma', \varphi', e_1,
  \lb a_3,\ldots a_n \rb),
\end{multline*}
where $\lb \sigma', \varphi', e_1\rb =
\invoke(\text{``eval''},\sigma,\varphi,a_1,\lb\rb)$.

\section*{Departures}
Today Lisp is over fifty years old, and Common Lisp is already half
that age. Aside from adding wholly new features, there is much room
for improvement in the traditional syntax of the language. Some common
names can be helpfully shortened (\texttt{fn} instead of
\texttt{lambda}, \texttt{ls} instead of \texttt{list}), and there are
several opportunities to reduce the sheer number of parentheses that a
programmer needs to type \cite{Graham}. Here we explain four such
opportunities that we have included in Yalie.

First, the functionality of the \texttt{cond} expression is
incorporated into \texttt{if} without changing the basic structure of
an \texttt{if} call. In particular, \texttt{if} can be made to take an
arbitrary number of test-consequence pairs, with an optional unpaired
expression interpreted as an alternative. For example:
\begin{quote}
\begin{verbatim}
(if test1 a
    test2 b
    test3 c
          d)
\end{verbatim}
\end{quote}

Second, parentheses inside the bindings of a \texttt{let} expression
are simply dropped. This gives the cleaner syntax:
\begin{quote}
\begin{verbatim}
(let (a 1
      b 2)
  (+ a b))
\end{verbatim}
\end{quote}
Yalie also extends the meaning of \texttt{let} in a different way. A
\texttt{let} expression with a single binding and no body creates a
local binding in the calling scope that persists until the end of that
scope. This allows the programmer to create a local variable without
adding a level of nesting and indentation, which can greatly improve
readability. When doing this, a further pair of parentheses is
omitted. Thus, the following is valid:
\begin{quote}
\begin{verbatim}
(let a 1)
(+ a 2)
\end{verbatim}
\end{quote}
As implemented in Yalie, \texttt{let} can create a new binding in this
way but cannot modify an existing one. (The \texttt{set} function
exists for that.) The purpose of the distinction is to separate
variable declaration for variable modification, so that typographical
errors in variable assignments will raise an exception instead of
silently creating a new variable. Yalie also follows the convention
that any non-functional operations be marked with ``set'' or ``!''.

Finally, the functionality of the \texttt{not} operator is extended to
include multiple arguments. When receiving more than one argument, not
interprets all its arguments as a function call and returns that
call's negation. For instance, the following returns a true value:
\begin{quote}
\begin{verbatim}
(not = 0 1)
\end{verbatim}
\end{quote}
In many common cases, this both increases readability and saves the
user two parentheses.

\section*{Objects: The Ultimate Lambda}
As both an illustrative example and a demonstration of the flexibility
of the object system, we detail the creation of a \texttt{lambda}
operator. Yalie has such an operator built in for convenience (under
the name \texttt{fn}), but we show how it can be defined within the
language. As a second example, we will also create a factorial method
for the integers.

We will need two methods that we did not formally define above,
\texttt{def} and \texttt{deform}. These methods allow the user to
define new methods and method forms in a given object. Recall that the
difference between a function and a form (or ``macro'') is that a
function implicitly evaluates its arguments while a form implicitly
evaluates its return. Methods and method forms work in the same way,
except that they are invoked by message passing. The syntax of
\texttt{def} and \texttt{deform} is identical to the \texttt{define}
operator in Scheme, and the return value of both methods is the
calling object.

The definition of \texttt{lambda} thus reads
\begin{quote}
\begin{verbatim}
(let lambda Form.child)
(lambda.deform (call args (rest body))
  `(let (ret Function.child)
     (ret.def (call ;args)
       ;body)))
\end{verbatim}
\end{quote}
The first expression creates a child object from the object that is
the parent of all forms and binds it to the name ``lambda''. We could
have used any object as the parent, but this way the new operator will
inherit whatever methods other forms inherit. The second expression
defines a \call\ method for the newly created object. Recall that
\call\ methods are invoked when S-expression are evaluated, and so
this method will define the functionality of \texttt{lambda}. The
method is a form, so its value is Yalie code to be executed at the end
of the call. This code can be confusing, because it is creating a
second child object---from the parent of functions, this time---with
its own call method. This new object is the anonymous function that
\texttt{lambda} returns. Note that the arguments and the function body
are just spliced into the call to the \texttt{def} method of the new
object.


\section*{Conclusions}
Several different interpreters were created at different stages in
this project, but the ``call'' and ``eval'' semantics as described in
this paper were only conceived for the final version. The ease of
coding these semantics relative to the more standard approach (using a
central eval loop) was striking, both in reduced programming time and
in reduced debugging time. These semantics are also far easier to
modify than any previous.

The language is still very small, so some of the benefits of the
object-based approach are not yet apparent. One tangible benefit is
that, despite having gutted the entire language to allow the
ubiquitous use of objects, the only difference visible in the global
namespace is the existence of the \msg\ function. All other object
facilities are confined within the method spaces. If we were to
further extend the language---with strings and file handles for
example---we would see the same benefits repeated, with new
functionality mostly confined to method spaces. Not only does this
approach keep the global namespace free of clutter, it also provides
helpful documentation in the form of method lists.

We have demonstrated the flexibility of the object-based approach, the
simplicity of the semantics has already made itself felt during the
implementation process. We look forward to finding new ways of
leveraging the object abstraction, both by itself and in conjunction
with Lisp's macro system.

\begin{thebibliography}{9}
\bibitem{Abadi} M. Abadi and L. Cardelli. \textit{A Theory of Objects.} New
  York: Springer, 1996.

\bibitem{Bruce} K. B. Bruce. \textit{Foundations of Object-Oriented
    Languages.} Cambridge, Massachusetts: MIT Press, 2002.

\bibitem{Graham} P. Graham. \textit{Arc at 3 Weeks.} November
  2001. Web. 8 May 2009.\\ $<$http://www.paulgraham.com/arcll1.html$>$.
\end{thebibliography}

\section*{Appendix: README}
\verbinput{README}

\section*{Appendix: builtins.py}
\verbinput{builtins.y}

\end{document}
